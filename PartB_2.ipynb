{"cells":[{"cell_type":"markdown","metadata":{"id":"NFVxWZGJxprU"},"source":["# CS4001/4042 Assignment 1, Part B, Q2\n","In Question B1, we used the Category Embedding model. This creates a feedforward neural network in which the categorical features get learnable embeddings. In this question, we will make use of a library called Pytorch-WideDeep. This library makes it easy to work with multimodal deep-learning problems combining images, text, and tables. We will just be utilizing the deeptabular component of this library through the TabMlp network:"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10512,"status":"ok","timestamp":1696759502046,"user":{"displayName":"Remelia Shirlley","userId":"09811854487608754037"},"user_tz":-480},"id":"EycCozG06Duu","outputId":"832066bf-f910-4f54-ebb9-bdabdd6a406c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytorch-widedeep\n","  Downloading pytorch_widedeep-1.3.2-py3-none-any.whl (21.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (1.5.3)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (1.23.5)\n","Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (1.11.3)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (1.2.2)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (4.3.2)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (3.6.1)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (4.8.0.76)\n","Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (0.5.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (4.66.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (0.15.2+cu118)\n","Collecting einops (from pytorch-widedeep)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (1.15.0)\n","Collecting torchmetrics (from pytorch-widedeep)\n","  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (9.0.0)\n","Collecting fastparquet>=0.8.1 (from pytorch-widedeep)\n","  Downloading fastparquet-2023.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cramjam>=2.3 (from fastparquet>=0.8.1->pytorch-widedeep)\n","  Downloading cramjam-2.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet>=0.8.1->pytorch-widedeep) (2023.6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet>=0.8.1->pytorch-widedeep) (23.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-widedeep) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-widedeep) (2023.3.post1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-widedeep) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-widedeep) (3.2.0)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pytorch-widedeep) (6.4.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (0.10.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (1.10.13)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (67.7.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (3.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-widedeep) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-widedeep) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-widedeep) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-widedeep) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-widedeep) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch-widedeep) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch-widedeep) (17.0.2)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics->pytorch-widedeep)\n","  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->pytorch-widedeep) (9.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.5->pytorch-widedeep) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytorch-widedeep) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytorch-widedeep) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytorch-widedeep) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytorch-widedeep) (2023.7.22)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->pytorch-widedeep) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->pytorch-widedeep) (0.1.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy->pytorch-widedeep) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->pytorch-widedeep) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch-widedeep) (1.3.0)\n","Installing collected packages: lightning-utilities, einops, cramjam, fastparquet, torchmetrics, pytorch-widedeep\n","Successfully installed cramjam-2.7.0 einops-0.7.0 fastparquet-2023.8.0 lightning-utilities-0.9.0 pytorch-widedeep-1.3.2 torchmetrics-1.2.0\n"]}],"source":["!pip install pytorch-widedeep"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23459,"status":"ok","timestamp":1696759528775,"user":{"displayName":"Remelia Shirlley","userId":"09811854487608754037"},"user_tz":-480},"id":"lq0elU0J53Yo","outputId":"3bd59979-6afb-48c2-f96d-9c2edf3c1e07"},"outputs":[{"name":"stderr","output_type":"stream","text":["<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n","<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n","<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n","<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n","<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"]}],"source":["SEED = 42\n","\n","import os\n","\n","import random\n","random.seed(SEED)\n","\n","import numpy as np\n","np.random.seed(SEED)\n","\n","import pandas as pd\n","\n","from pytorch_widedeep.preprocessing import TabPreprocessor\n","from pytorch_widedeep.models import TabMlp, WideDeep\n","from pytorch_widedeep import Trainer\n","from pytorch_widedeep.metrics import R2Score"]},{"cell_type":"markdown","metadata":{"id":"aU3xdVpwzuLx"},"source":[">Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from the year 2020 and before as training data, and entries from 2021 and after as the test data."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23563,"status":"ok","timestamp":1696759552320,"user":{"displayName":"Remelia Shirlley","userId":"09811854487608754037"},"user_tz":-480},"id":"z9ZH7W1mlMGs","outputId":"3ee100da-25a1-4347-aa36-f6180b317062"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n","/usr/local/lib/python3.10/dist-packages/pexpect/popen_spawn.py:60: DeprecationWarning: setDaemon() is deprecated, set the daemon attribute instead\n","  self._read_thread.setDaemon(True)\n"]},{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1104,"status":"ok","timestamp":1696759553408,"user":{"displayName":"Remelia Shirlley","userId":"09811854487608754037"},"user_tz":-480},"id":"_oYG6lNIh7Mp"},"outputs":[],"source":["df = pd.read_csv('/content/drive/MyDrive/programming_assignment/hdb_price_prediction.csv')\n","\n","# TODO: Enter your code here\n","df.drop(columns=['full_address','nearest_stn'],inplace=True)\n","\n","train=df[df['year']<=2020].drop(columns=['year'])\n","test=df[df['year']>=2021].drop(columns=['year'])"]},{"cell_type":"markdown","metadata":{"id":"m_q9PoR50JAA"},"source":[">Refer to the documentation of Pytorch-WideDeep and perform the following tasks:\n","https://pytorch-widedeep.readthedocs.io/en/latest/index.html\n","* Use [**TabPreprocessor**](https://pytorch-widedeep.readthedocs.io/en/latest/examples/01_preprocessors_and_utils.html#2-tabpreprocessor) to create the deeptabular component using the continuous\n","features and the categorical features. Use this component to transform the training dataset.\n","* Create the [**TabMlp**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/model_components.html#pytorch_widedeep.models.tabular.mlp.tab_mlp.TabMlp) model with 2 linear layers in the MLP, with 200 and 100 neurons respectively.\n","* Create a [**Trainer**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/trainer.html#pytorch_widedeep.training.Trainer) for the training of the created TabMlp model with the root mean squared error (RMSE) cost function. Train the model for 100 epochs using this trainer, keeping a batch size of 64. (Note: set the *num_workers* parameter to 0.)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1479840,"status":"ok","timestamp":1696761033245,"user":{"displayName":"Remelia Shirlley","userId":"09811854487608754037"},"user_tz":-480},"id":"ZBY1iqUXtYWn","outputId":"7a7486d6-8f9d-4bd7-a285-94a3241bb101"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n","/usr/local/lib/python3.10/dist-packages/pytorch_widedeep/preprocessing/tab_preprocessor.py:334: UserWarning: Continuous columns will not be normalised\n","  warnings.warn(\"Continuous columns will not be normalised\")\n","epoch 1: 100%|██████████| 1366/1366 [00:17<00:00, 76.32it/s, loss=2.27e+5, metrics={'r2': -2.1974}]\n","epoch 2: 100%|██████████| 1366/1366 [00:15<00:00, 86.24it/s, loss=1.01e+5, metrics={'r2': 0.5059}]\n","epoch 3: 100%|██████████| 1366/1366 [00:14<00:00, 94.71it/s, loss=8.95e+4, metrics={'r2': 0.6244}]\n","epoch 4: 100%|██████████| 1366/1366 [00:14<00:00, 95.57it/s, loss=8.23e+4, metrics={'r2': 0.6899}]\n","epoch 5: 100%|██████████| 1366/1366 [00:14<00:00, 93.22it/s, loss=7.83e+4, metrics={'r2': 0.7236}] \n","epoch 6: 100%|██████████| 1366/1366 [00:14<00:00, 94.88it/s, loss=7.48e+4, metrics={'r2': 0.7493}] \n","epoch 7: 100%|██████████| 1366/1366 [00:13<00:00, 98.08it/s, loss=7.27e+4, metrics={'r2': 0.7648}]\n","epoch 8: 100%|██████████| 1366/1366 [00:14<00:00, 97.52it/s, loss=7.14e+4, metrics={'r2': 0.7735}]\n","epoch 9: 100%|██████████| 1366/1366 [00:14<00:00, 96.02it/s, loss=7.03e+4, metrics={'r2': 0.7805}]\n","epoch 10: 100%|██████████| 1366/1366 [00:14<00:00, 94.45it/s, loss=6.91e+4, metrics={'r2': 0.7883}]\n","epoch 11: 100%|██████████| 1366/1366 [00:14<00:00, 94.52it/s, loss=6.86e+4, metrics={'r2': 0.7907}]\n","epoch 12: 100%|██████████| 1366/1366 [00:14<00:00, 95.70it/s, loss=6.81e+4, metrics={'r2': 0.7934}]\n","epoch 13: 100%|██████████| 1366/1366 [00:14<00:00, 93.77it/s, loss=6.74e+4, metrics={'r2': 0.7982}]\n","epoch 14: 100%|██████████| 1366/1366 [00:14<00:00, 94.48it/s, loss=6.7e+4, metrics={'r2': 0.7999}]\n","epoch 15: 100%|██████████| 1366/1366 [00:14<00:00, 94.44it/s, loss=6.66e+4, metrics={'r2': 0.8022}] \n","epoch 16: 100%|██████████| 1366/1366 [00:14<00:00, 93.67it/s, loss=6.63e+4, metrics={'r2': 0.8041}]\n","epoch 17: 100%|██████████| 1366/1366 [00:14<00:00, 94.46it/s, loss=6.58e+4, metrics={'r2': 0.8069}]\n","epoch 18: 100%|██████████| 1366/1366 [00:14<00:00, 94.57it/s, loss=6.52e+4, metrics={'r2': 0.8096}] \n","epoch 19: 100%|██████████| 1366/1366 [00:14<00:00, 92.38it/s, loss=6.54e+4, metrics={'r2': 0.8087}] \n","epoch 20: 100%|██████████| 1366/1366 [00:14<00:00, 91.73it/s, loss=6.53e+4, metrics={'r2': 0.8091}]\n","epoch 21: 100%|██████████| 1366/1366 [00:14<00:00, 93.74it/s, loss=6.48e+4, metrics={'r2': 0.8124}]\n","epoch 22: 100%|██████████| 1366/1366 [00:14<00:00, 95.99it/s, loss=6.45e+4, metrics={'r2': 0.8139}]\n","epoch 23: 100%|██████████| 1366/1366 [00:14<00:00, 95.19it/s, loss=6.43e+4, metrics={'r2': 0.8149}]\n","epoch 24: 100%|██████████| 1366/1366 [00:14<00:00, 91.82it/s, loss=6.41e+4, metrics={'r2': 0.8155}]\n","epoch 25: 100%|██████████| 1366/1366 [00:14<00:00, 95.71it/s, loss=6.39e+4, metrics={'r2': 0.8173}]\n","epoch 26: 100%|██████████| 1366/1366 [00:13<00:00, 100.42it/s, loss=6.35e+4, metrics={'r2': 0.8192}]\n","epoch 27: 100%|██████████| 1366/1366 [00:14<00:00, 95.83it/s, loss=6.36e+4, metrics={'r2': 0.8187}]\n","epoch 28: 100%|██████████| 1366/1366 [00:14<00:00, 94.02it/s, loss=6.31e+4, metrics={'r2': 0.821}] \n","epoch 29: 100%|██████████| 1366/1366 [00:14<00:00, 96.63it/s, loss=6.31e+4, metrics={'r2': 0.8209}]\n","epoch 30: 100%|██████████| 1366/1366 [00:14<00:00, 96.31it/s, loss=6.29e+4, metrics={'r2': 0.8222}]\n","epoch 31: 100%|██████████| 1366/1366 [00:14<00:00, 93.79it/s, loss=6.28e+4, metrics={'r2': 0.8227}]\n","epoch 32: 100%|██████████| 1366/1366 [00:14<00:00, 92.62it/s, loss=6.26e+4, metrics={'r2': 0.8242}]\n","epoch 33: 100%|██████████| 1366/1366 [00:14<00:00, 93.39it/s, loss=6.24e+4, metrics={'r2': 0.8243}]\n","epoch 34: 100%|██████████| 1366/1366 [00:14<00:00, 94.73it/s, loss=6.23e+4, metrics={'r2': 0.825}]\n","epoch 35: 100%|██████████| 1366/1366 [00:14<00:00, 94.86it/s, loss=6.21e+4, metrics={'r2': 0.8264}]\n","epoch 36: 100%|██████████| 1366/1366 [00:14<00:00, 93.03it/s, loss=6.19e+4, metrics={'r2': 0.8275}]\n","epoch 37: 100%|██████████| 1366/1366 [00:14<00:00, 96.34it/s, loss=6.19e+4, metrics={'r2': 0.827}]\n","epoch 38: 100%|██████████| 1366/1366 [00:14<00:00, 94.82it/s, loss=6.17e+4, metrics={'r2': 0.8282}]\n","epoch 39: 100%|██████████| 1366/1366 [00:15<00:00, 89.72it/s, loss=6.16e+4, metrics={'r2': 0.8286}]\n","epoch 40: 100%|██████████| 1366/1366 [00:14<00:00, 93.94it/s, loss=6.14e+4, metrics={'r2': 0.8298}] \n","epoch 41: 100%|██████████| 1366/1366 [00:14<00:00, 91.61it/s, loss=6.11e+4, metrics={'r2': 0.8311}]\n","epoch 42: 100%|██████████| 1366/1366 [00:13<00:00, 98.19it/s, loss=6.09e+4, metrics={'r2': 0.8322}]\n","epoch 43: 100%|██████████| 1366/1366 [00:14<00:00, 93.14it/s, loss=6.09e+4, metrics={'r2': 0.8322}]\n","epoch 44: 100%|██████████| 1366/1366 [00:14<00:00, 91.18it/s, loss=6.06e+4, metrics={'r2': 0.8337}]\n","epoch 45: 100%|██████████| 1366/1366 [00:14<00:00, 91.94it/s, loss=6.04e+4, metrics={'r2': 0.8344}]\n","epoch 46: 100%|██████████| 1366/1366 [00:14<00:00, 97.09it/s, loss=6.04e+4, metrics={'r2': 0.8345}]\n","epoch 47: 100%|██████████| 1366/1366 [00:14<00:00, 92.36it/s, loss=6.01e+4, metrics={'r2': 0.8362}]\n","epoch 48: 100%|██████████| 1366/1366 [00:14<00:00, 92.49it/s, loss=6.01e+4, metrics={'r2': 0.8363}] \n","epoch 49: 100%|██████████| 1366/1366 [00:14<00:00, 91.63it/s, loss=6e+4, metrics={'r2': 0.8365}] \n","epoch 50: 100%|██████████| 1366/1366 [00:13<00:00, 98.71it/s, loss=5.98e+4, metrics={'r2': 0.8378}]\n","epoch 51: 100%|██████████| 1366/1366 [00:14<00:00, 94.59it/s, loss=5.97e+4, metrics={'r2': 0.8378}]\n","epoch 52: 100%|██████████| 1366/1366 [00:14<00:00, 93.59it/s, loss=5.97e+4, metrics={'r2': 0.8381}] \n","epoch 53: 100%|██████████| 1366/1366 [00:15<00:00, 90.55it/s, loss=5.94e+4, metrics={'r2': 0.84}]\n","epoch 54: 100%|██████████| 1366/1366 [00:14<00:00, 96.02it/s, loss=5.93e+4, metrics={'r2': 0.8402}]\n","epoch 55: 100%|██████████| 1366/1366 [00:14<00:00, 95.62it/s, loss=5.92e+4, metrics={'r2': 0.8406}]\n","epoch 56: 100%|██████████| 1366/1366 [00:14<00:00, 94.02it/s, loss=5.9e+4, metrics={'r2': 0.8414}]\n","epoch 57: 100%|██████████| 1366/1366 [00:14<00:00, 94.80it/s, loss=5.89e+4, metrics={'r2': 0.8419}]\n","epoch 58: 100%|██████████| 1366/1366 [00:14<00:00, 92.26it/s, loss=5.9e+4, metrics={'r2': 0.8419}]\n","epoch 59: 100%|██████████| 1366/1366 [00:14<00:00, 93.99it/s, loss=5.88e+4, metrics={'r2': 0.8425}]\n","epoch 60: 100%|██████████| 1366/1366 [00:14<00:00, 92.09it/s, loss=5.87e+4, metrics={'r2': 0.8433}] \n","epoch 61: 100%|██████████| 1366/1366 [00:15<00:00, 90.24it/s, loss=5.86e+4, metrics={'r2': 0.8438}]\n","epoch 62: 100%|██████████| 1366/1366 [00:13<00:00, 97.60it/s, loss=5.85e+4, metrics={'r2': 0.8445}]\n","epoch 63: 100%|██████████| 1366/1366 [00:14<00:00, 93.91it/s, loss=5.84e+4, metrics={'r2': 0.8448}]\n","epoch 64: 100%|██████████| 1366/1366 [00:14<00:00, 93.65it/s, loss=5.84e+4, metrics={'r2': 0.8446}]\n","epoch 65: 100%|██████████| 1366/1366 [00:14<00:00, 93.79it/s, loss=5.81e+4, metrics={'r2': 0.8464}]\n","epoch 66: 100%|██████████| 1366/1366 [00:14<00:00, 92.65it/s, loss=5.77e+4, metrics={'r2': 0.8484}]\n","epoch 67: 100%|██████████| 1366/1366 [00:16<00:00, 83.91it/s, loss=5.76e+4, metrics={'r2': 0.8492}]\n","epoch 68: 100%|██████████| 1366/1366 [00:14<00:00, 92.52it/s, loss=5.72e+4, metrics={'r2': 0.8514}]\n","epoch 69: 100%|██████████| 1366/1366 [00:15<00:00, 89.37it/s, loss=5.67e+4, metrics={'r2': 0.8536}]\n","epoch 70: 100%|██████████| 1366/1366 [00:15<00:00, 87.42it/s, loss=5.59e+4, metrics={'r2': 0.858}]\n","epoch 71: 100%|██████████| 1366/1366 [00:14<00:00, 95.29it/s, loss=5.53e+4, metrics={'r2': 0.8608}]\n","epoch 72: 100%|██████████| 1366/1366 [00:14<00:00, 94.59it/s, loss=5.46e+4, metrics={'r2': 0.8647}]\n","epoch 73: 100%|██████████| 1366/1366 [00:14<00:00, 92.00it/s, loss=5.39e+4, metrics={'r2': 0.868}]\n","epoch 74: 100%|██████████| 1366/1366 [00:14<00:00, 94.42it/s, loss=5.33e+4, metrics={'r2': 0.8712}]\n","epoch 75: 100%|██████████| 1366/1366 [00:14<00:00, 94.43it/s, loss=5.28e+4, metrics={'r2': 0.8732}]\n","epoch 76: 100%|██████████| 1366/1366 [00:14<00:00, 92.72it/s, loss=5.25e+4, metrics={'r2': 0.8745}]\n","epoch 77: 100%|██████████| 1366/1366 [00:14<00:00, 91.47it/s, loss=5.22e+4, metrics={'r2': 0.8762}]\n","epoch 78: 100%|██████████| 1366/1366 [00:14<00:00, 95.03it/s, loss=5.21e+4, metrics={'r2': 0.8764}]\n","epoch 79: 100%|██████████| 1366/1366 [00:14<00:00, 93.04it/s, loss=5.19e+4, metrics={'r2': 0.8777}]\n","epoch 80: 100%|██████████| 1366/1366 [00:14<00:00, 95.14it/s, loss=5.17e+4, metrics={'r2': 0.8783}]\n","epoch 81: 100%|██████████| 1366/1366 [00:15<00:00, 89.56it/s, loss=5.15e+4, metrics={'r2': 0.8791}]\n","epoch 82: 100%|██████████| 1366/1366 [00:15<00:00, 90.45it/s, loss=5.15e+4, metrics={'r2': 0.8792}]\n","epoch 83: 100%|██████████| 1366/1366 [00:14<00:00, 94.30it/s, loss=5.15e+4, metrics={'r2': 0.8793}]\n","epoch 84: 100%|██████████| 1366/1366 [00:15<00:00, 90.56it/s, loss=5.13e+4, metrics={'r2': 0.8804}]\n","epoch 85: 100%|██████████| 1366/1366 [00:14<00:00, 94.20it/s, loss=5.11e+4, metrics={'r2': 0.8812}]\n","epoch 86: 100%|██████████| 1366/1366 [00:14<00:00, 91.96it/s, loss=5.12e+4, metrics={'r2': 0.8804}]\n","epoch 87: 100%|██████████| 1366/1366 [00:14<00:00, 93.86it/s, loss=5.09e+4, metrics={'r2': 0.882}]\n","epoch 88: 100%|██████████| 1366/1366 [00:14<00:00, 92.11it/s, loss=5.1e+4, metrics={'r2': 0.8817}]\n","epoch 89: 100%|██████████| 1366/1366 [00:14<00:00, 92.97it/s, loss=5.08e+4, metrics={'r2': 0.8825}] \n","epoch 90: 100%|██████████| 1366/1366 [00:14<00:00, 93.87it/s, loss=5.07e+4, metrics={'r2': 0.8832}]\n","epoch 91: 100%|██████████| 1366/1366 [00:13<00:00, 98.68it/s, loss=5.06e+4, metrics={'r2': 0.8834}]\n","epoch 92: 100%|██████████| 1366/1366 [00:15<00:00, 90.98it/s, loss=5.04e+4, metrics={'r2': 0.8841}]\n","epoch 93: 100%|██████████| 1366/1366 [00:14<00:00, 93.56it/s, loss=5.05e+4, metrics={'r2': 0.884}]\n","epoch 94: 100%|██████████| 1366/1366 [00:15<00:00, 90.84it/s, loss=5.05e+4, metrics={'r2': 0.8842}]\n","epoch 95: 100%|██████████| 1366/1366 [00:14<00:00, 92.08it/s, loss=5.03e+4, metrics={'r2': 0.8846}]\n","epoch 96: 100%|██████████| 1366/1366 [00:14<00:00, 97.18it/s, loss=5.03e+4, metrics={'r2': 0.885}]\n","epoch 97: 100%|██████████| 1366/1366 [00:14<00:00, 95.96it/s, loss=5.01e+4, metrics={'r2': 0.886}] \n","epoch 98: 100%|██████████| 1366/1366 [00:14<00:00, 93.17it/s, loss=5e+4, metrics={'r2': 0.8861}]\n","epoch 99: 100%|██████████| 1366/1366 [00:14<00:00, 92.69it/s, loss=5.01e+4, metrics={'r2': 0.8857}]\n","epoch 100: 100%|██████████| 1366/1366 [00:14<00:00, 93.62it/s, loss=5e+4, metrics={'r2': 0.8862}]\n","predict: 100%|██████████| 1128/1128 [00:05<00:00, 206.08it/s]\n"]}],"source":["# TODO: Enter your code here\n","from pytorch_widedeep.losses import RMSELoss\n","\n","cat_embed_cols = ['month', 'town', 'flat_model_type', 'storey_range']\n","continuous_cols = ['dist_to_nearest_stn', 'dist_to_dhoby', 'degree_centrality', 'eigenvector_centrality', 'remaining_lease_years', 'floor_area_sqm']\n","target = \"resale_price\"\n","target = train[target].values\n","\n","tab_preprocessor = TabPreprocessor(\n","    cat_embed_cols=cat_embed_cols, continuous_cols=continuous_cols  # type: ignore[arg-type]\n",")\n","X_tab = tab_preprocessor.fit_transform(train)\n","\n","# build the model\n","tab_mlp = TabMlp(\n","    column_idx=tab_preprocessor.column_idx,\n","    cat_embed_input=tab_preprocessor.cat_embed_input,\n","    continuous_cols=continuous_cols,\n","    mlp_hidden_dims=[200,100] #2 linear layers with 200 and 100 neurons\n",")\n","\n","# train and validate\n","model = WideDeep(deeptabular=tab_mlp)\n","\n","trainer = Trainer(model, cost_function=\"root_mean_squared_error\", metrics=[R2Score], num_workers=0)\n","trainer.fit(\n","    X_tab=X_tab,\n","    target=target,\n","    n_epochs=100,\n","    batch_size=64,\n",")\n","\n","# predict on test\n","X_tab_te = tab_preprocessor.transform(test)\n","preds = trainer.predict(X_tab=X_tab_te)"]},{"cell_type":"markdown","metadata":{"id":"V46s-MdM0y5c"},"source":[">Report the test RMSE and the test R2 value that you obtained."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1696761902696,"user":{"displayName":"Remelia Shirlley","userId":"09811854487608754037"},"user_tz":-480},"id":"KAhAgvMC07g6","outputId":"822b666f-4feb-4b55-e894-39d2f1410632"},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE: 97363.4435333663\n","R^2: 0.6687999595044318\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["# TODO: Enter your code here\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","rmse=np.sqrt(mean_squared_error(test['resale_price'],preds))\n","r2=r2_score(test['resale_price'],preds)\n","\n","print(f'RMSE: {rmse}')\n","print(f'R^2: {r2}')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
